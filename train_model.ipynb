{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWe4aiX2qbFT"
      },
      "source": [
        "Some dependencies..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4VztAI8o2fJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import cat\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "!pip install rasterio\n",
        "import rasterio\n",
        "!pip install pytorch_lightning\n",
        "import pytorch_lightning\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi9V5iGi7dKw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGo-bvHYp04A"
      },
      "source": [
        "Create util functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jc3YZxRupj28"
      },
      "outputs": [],
      "source": [
        "def extract_paths(directory):\n",
        "    \"\"\"\n",
        "    The function reads all files names in the given root directory and returns two\n",
        "    dataframe: contents and masks.\n",
        "\n",
        "    :param directory: str\n",
        "    :return:\n",
        "    contents:\n",
        "            dataframe containing info of content image paths and content image id\n",
        "    masks:\n",
        "            dataframe contain info of mask image path and mask image id\n",
        "    \"\"\"\n",
        "\n",
        "    masks = []\n",
        "    contents = []\n",
        "    # walk through all files in the given directory\n",
        "    for (root, dirs, files) in os.walk(directory, topdown=False):\n",
        "        # extract patient id from root path\n",
        "        patient_id = root.split(\"/\")[-1]\n",
        "\n",
        "        # skip the main file\n",
        "        if \"TCGA\" not in patient_id:\n",
        "            continue\n",
        "\n",
        "        for file_name in files:\n",
        "            # full directory string for the file\n",
        "            full_dir = os.path.join(root, file_name)\n",
        "            if \"mask\" in full_dir:\n",
        "                mask_id = int(full_dir[77:-9])\n",
        "                masks.extend([patient_id, full_dir, mask_id])\n",
        "            else:\n",
        "                content_id = int(full_dir[77:-4])\n",
        "                contents.extend([patient_id, full_dir, content_id])\n",
        "\n",
        "    # split patient_id and full_dir\n",
        "    mask_patient_ids = masks[::3]\n",
        "    mask_full_dirs = masks[1::3]\n",
        "    mask_ids = masks[2::3]\n",
        "    content_patient_ids = contents[::3]\n",
        "    content_full_dirs = contents[1::3]\n",
        "    content_ids = contents[2::3]\n",
        "\n",
        "    # combine two list (patient_id and full_dir) into a dataframe\n",
        "    # 1. convert two list into a dictionary\n",
        "    masks = {\"patient_id\": mask_patient_ids,\n",
        "             \"full_mask_dir\": mask_full_dirs,\n",
        "             \"mask_id\": mask_ids}\n",
        "    contents = {\"patient_id\": content_patient_ids,\n",
        "                \"full_content_dir\": content_full_dirs,\n",
        "                \"content_id\": content_ids}\n",
        "    # 2. convert the dict into a dataframe\n",
        "    masks = pd.DataFrame(masks)\n",
        "    contents = pd.DataFrame(contents)\n",
        "\n",
        "    return masks, contents\n",
        "\n",
        "\n",
        "def sort_combine_paths(masks, contents):\n",
        "    \"\"\"\n",
        "    The function takes path dataframe for mask images and path dataframe for content images,\n",
        "    sorts and combines the two dataframes so that the mask file path and the content file\n",
        "    path are matched in a single row in a single dataframe\n",
        "\n",
        "    :param masks: dataframe\n",
        "    :param contents: dataframe\n",
        "    :return: dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    # sort dataframes with a key function, making sure that mask path and\n",
        "    # content path is corresponding to each other at each row index\n",
        "    contents = contents.sort_values(by=[\"patient_id\", \"content_id\"], ignore_index=True)\n",
        "    masks = masks.sort_values(by=[\"patient_id\", \"mask_id\"], ignore_index=True)\n",
        "    # contents = sorted(original_contents[\"full_content_dir\"].values, key=lambda x: int(x[56:-4]))\n",
        "    # masks = sorted(masks[\"full_mask_dir\"].values, key=lambda x: int(x[56:-9]))\n",
        "\n",
        "    # combine two dataframe together\n",
        "    content_paths = contents.iloc[:, 1]\n",
        "    mask_paths = masks.iloc[:, 1]\n",
        "    patient_ids = contents.iloc[:, 0]\n",
        "    dir_df = pd.DataFrame({\n",
        "        \"patient_id\": patient_ids,\n",
        "        \"content_path\": content_paths,\n",
        "        \"mask_path\": mask_paths\n",
        "    })\n",
        "\n",
        "    # randomly select a row, check if paths at the same row are not matched\n",
        "    idx = random.randint(0, len(dir_df) - 1)\n",
        "    content_path = dir_df.iloc[idx, 1]\n",
        "    mask_path = dir_df.iloc[idx, 2]\n",
        "    if content_path[:-4] != mask_path[:-9]:\n",
        "        raise Exception(\"Something failed for matching process\")\n",
        "\n",
        "    return dir_df.sample(frac=1)  # shuffle dataframe\n",
        "\n",
        "\n",
        "def load_data(df_dir: pd.DataFrame, start_idx: int = 0, shuffle: bool = False, batch_size: int = 1):\n",
        "    \"\"\"\n",
        "    The function read images by paths in df_dir and return content image arrays and mask image arrays.\n",
        "    :param start_idx: int\n",
        "    :param batch_size: int\n",
        "    :param shuffle: boolean\n",
        "    :param df_dir: dataframe\n",
        "    :return: ndarray, ndarray\n",
        "    \"\"\"\n",
        "    # check if random shuffle\n",
        "    if shuffle:\n",
        "        df_dir.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # check if batch size is valid\n",
        "    if batch_size > df_dir.shape[0]:\n",
        "        raise IndexError(\"batch size is too large\")\n",
        "\n",
        "    # ignore warning\n",
        "    warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
        "\n",
        "    # read images an convert into tensor\n",
        "    content_images = []\n",
        "    mask_images = []\n",
        "    for i in range(batch_size):\n",
        "        # read content image\n",
        "        content_path = df_dir.iloc[start_idx + i, 1]\n",
        "        mask_path = df_dir.iloc[start_idx + i, 2]\n",
        "\n",
        "        # read image by rasterio\n",
        "        content_image = rasterio.open(content_path).read()\n",
        "        mask_image = rasterio.open(mask_path).read()\n",
        "        content_images.append(content_image)\n",
        "        mask_images.append(mask_image)\n",
        "\n",
        "    return np.array(content_images), np.array(mask_images)\n",
        "\n",
        "\n",
        "def adjust_data(img, mask):\n",
        "    \"\"\"\n",
        "    The function rescaled data in img to [0, 1] and convert data in mask to binary\n",
        "    :param img: dataframe\n",
        "    :param mask: dataframe\n",
        "    :return: dataframes\n",
        "    \"\"\"\n",
        "    img = img / 255\n",
        "    mask = mask / 255\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "\n",
        "    return img, mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3hUM14ZqA8K"
      },
      "source": [
        "Build my customized nn layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2JDsCSB0pzBx"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"\n",
        "    double_conv layer contains two convolutional layer\n",
        "    Conv2d -> BatchNorm2d -> ReLU -> Conv2d -> BatchNorm2d -> ReLU\n",
        "    the layer does not contain a max pooling layer because its output is useful for up-sampling\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        # inherited properties passed from nn.Module\n",
        "        super(DoubleConv, self).__init__()\n",
        "        # define mid channel\n",
        "        self.mid_channel = out_channel\n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.double_conv = nn.Sequential(\n",
        "            # out_channel means how many convolutional kernels are we using\n",
        "            # padding = 'same' keeps image size (HxW)\n",
        "            nn.Conv2d(self.in_channel, self.mid_channel, kernel_size=3, padding='same'),\n",
        "            # batch normalization making sure values in feature map follows normal distribution\n",
        "            nn.BatchNorm2d(self.mid_channel),\n",
        "            # an activation layer after each convolutional layer. Turn on inplace to save memory\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(self.mid_channel, self.out_channel, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(self.out_channel),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_layer):\n",
        "        \"\"\"\n",
        "        The forward function passes input_layer through the double convolutional layer.\n",
        "        :param input_layer: tensor [batch size, input channel size, H, W]\n",
        "        :return: tensor [batch size, output channel size, H, W]\n",
        "        \"\"\"\n",
        "        output_layer = self.double_conv(input_layer)\n",
        "        return output_layer\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        # out_channel is 2 * in_channel\n",
        "        super(Up, self).__init__()\n",
        "        self.mid_channel = out_channel\n",
        "        # an up-conv layer\n",
        "        # H_out = (H_in - 1) * stride - 2 * padding + kernel_size\n",
        "        self.up = nn.ConvTranspose2d(in_channel, self.mid_channel, stride=2, kernel_size=2)\n",
        "        # a DoubleConv layer\n",
        "        # input channel size is 2 * mid channel size because we need to concatenate\n",
        "        self.double_conv = DoubleConv(self.mid_channel * 2, out_channel)\n",
        "\n",
        "    def forward(self, input_layer1, input_layer2):\n",
        "        input_layer1 = self.up(input_layer1)\n",
        "        input_layer = cat((input_layer1, input_layer2), dim=1)  # axis: channel\n",
        "        output_layer = self.double_conv(input_layer)\n",
        "        return output_layer\n",
        "\n",
        "\n",
        "class MyLoss(nn.Module):\n",
        "    def __init__(self, dice_loss_mode: bool = True, smooth: float = 0.01):\n",
        "        super(MyLoss, self).__init__()\n",
        "        self.dice_loss_mode = dice_loss_mode\n",
        "        self.smooth = smooth\n",
        "        return\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "\n",
        "        if self.dice_loss_mode:\n",
        "            # flatten pred and target\n",
        "            pred_flattened = pred.reshape(-1)\n",
        "            target_flattened = target.reshape(-1)\n",
        "\n",
        "            # intersection\n",
        "            intersect = torch.dot(pred_flattened, target_flattened)\n",
        "\n",
        "            # sum\n",
        "            sum_two = torch.sum(pred_flattened) + torch.sum(target_flattened)\n",
        "\n",
        "            # dice_score = 2 * |A∩B| / (|A| + |B|)\n",
        "            loss = - (2 * intersect + self.smooth) / (sum_two + self.smooth)\n",
        "        else:\n",
        "            pred = torch.round(pred)  # convert into binary mask\n",
        "\n",
        "            # intersection\n",
        "            intersect = torch.sum(pred * target)\n",
        "\n",
        "            # union\n",
        "            union = torch.ceil((pred + target)/2)\n",
        "\n",
        "            # Jaccard = |A∩B| / |A∪B|\n",
        "            loss = - (intersect + self.smooth) / (torch.sum(union) + self.smooth)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rnmB89mjG4LF"
      },
      "outputs": [],
      "source": [
        "def iou_score(pred, target, smooth: int = 0.001):\n",
        "    pred = torch.round(pred)  # convert into binary mask\n",
        "\n",
        "    # intersection\n",
        "    intersect = torch.sum(pred * target)\n",
        "\n",
        "    # union\n",
        "    union = torch.ceil((pred + target)/2)\n",
        "\n",
        "    # Jaccard = |A∩B| / |A∪B|\n",
        "    iou_score = (intersect + smooth) / (torch.sum(union) + smooth)\n",
        "\n",
        "    return iou_score\n",
        "\n",
        "def dice_score(pred, target, smooth: int=0.001):\n",
        "    # flatten pred and target\n",
        "    pred_flattened = pred.reshape(-1)\n",
        "    target_flattened = target.reshape(-1)\n",
        "\n",
        "    # intersection\n",
        "    intersect = torch.dot(pred_flattened, target_flattened)\n",
        "\n",
        "    # sum\n",
        "    sum_two = torch.sum(pred_flattened) + torch.sum(target_flattened)\n",
        "\n",
        "    # dice_score = 2 * |A∩B| / (|A| + |B|)\n",
        "    dice_score = (2 * intersect + smooth) / (sum_two + smooth)\n",
        "    return dice_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fSy0r6xqE--"
      },
      "source": [
        "Build my CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cnqC8iPhqHWl"
      },
      "outputs": [],
      "source": [
        "class Unet(nn.Module):\n",
        "    def __init__(self, in_channel):\n",
        "        super(Unet, self).__init__()\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.down1 = DoubleConv(in_channel, 32)\n",
        "        self.down2 = DoubleConv(32, 64)\n",
        "        self.down3 = DoubleConv(64, 128)\n",
        "        self.down4 = DoubleConv(128, 256)\n",
        "        self.down5 = DoubleConv(256, 512)\n",
        "        self.up6 = Up(512, 256)\n",
        "        self.up7 = Up(256, 128)\n",
        "        self.up8 = Up(128, 64)\n",
        "        self.up9 = Up(64, 32)\n",
        "        # output a single channel (binary)\n",
        "        self.up10 = nn.ConvTranspose2d(32, 1, stride=1, kernel_size=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, im_input):\n",
        "        im_down1 = self.down1(im_input)\n",
        "        im_down1_pooled = self.max_pool(im_down1)\n",
        "        im_down2 = self.down2(im_down1_pooled)\n",
        "        im_down2_pooled = self.max_pool(im_down2)\n",
        "        im_down3 = self.down3(im_down2_pooled)\n",
        "        im_down3_pooled = self.max_pool(im_down3)\n",
        "        im_down4 = self.down4(im_down3_pooled)\n",
        "        im_down4_pooled = self.max_pool(im_down4)\n",
        "        im_down5 = self.down5(im_down4_pooled)  # max pooling is not followed\n",
        "        im_up6 = self.up6(im_down5, im_down4)\n",
        "        im_up7 = self.up7(im_up6, im_down3)\n",
        "        im_up8 = self.up8(im_up7, im_down2)\n",
        "        im_up9 = self.up9(im_up8, im_down1)\n",
        "        im_output = self.up10(im_up9)\n",
        "        return self.sigmoid(im_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pDXh96JqJuD"
      },
      "source": [
        "Create a validation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T7IpFZzXqMV0"
      },
      "outputs": [],
      "source": [
        "def validation(unet: Unet, validation_img: pd.DataFrame, device, batch_size: int = 10):\n",
        "    # load data into device\n",
        "    validation_content, validation_mask = load_data(validation_img, shuffle=True, batch_size=batch_size)  #validation_img.shape[0]\n",
        "    validation_content, validation_mask = adjust_data(validation_content, validation_mask)\n",
        "    validation_content_tensor = torch.from_numpy(validation_content).to(device).float()\n",
        "    validation_mask_tensor = torch.from_numpy(validation_mask).to(device).float()\n",
        "\n",
        "    unet.eval()  # close BatchNorm2d during validation\n",
        "    # calculate prediction of validation image with no autograd mechanism\n",
        "    with torch.no_grad():\n",
        "        pred_mask_tensor = unet.forward(validation_content_tensor)\n",
        "        pred_mask_tensor = torch.round(pred_mask_tensor)\n",
        "        pred_dice_score = dice_score(pred_mask_tensor, validation_mask_tensor)\n",
        "        pred_iou_score = iou_score(pred_mask_tensor, validation_mask_tensor)\n",
        "\n",
        "    unet.train()  # convert back to training mode\n",
        "    return pred_dice_score, pred_iou_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7FuuH37qPDi"
      },
      "source": [
        "Create a training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k4GZyhQ1qTh_"
      },
      "outputs": [],
      "source": [
        "def train(train_img: pd.DataFrame,\n",
        "          validation_img: pd.DataFrame,\n",
        "          epoch: int = 1,\n",
        "          lrate: float = 0.0001,\n",
        "          shuffle: bool = False,\n",
        "          batch_size: int = 32,\n",
        "          device_: str = 'cpu',\n",
        "          use_cel: bool = True):\n",
        "    # define device\n",
        "    if device_ != 'cuda' and device_ != 'cpu':\n",
        "        raise ValueError(\"invalid device\")\n",
        "    if not torch.cuda.is_available() and device_ == 'cuda':\n",
        "        device = torch.device('cpu')\n",
        "    else:\n",
        "        device = torch.device(device_)\n",
        "    print(\"using\", device.type)\n",
        "\n",
        "    iteration = train_img.shape[0] // batch_size  # how many iterations do we need to go through all data\n",
        "\n",
        "    # customize training process\n",
        "    interval = 20\n",
        "    # logging.basicConfig(level=logging.INFO, filename='./content/drive/MyDrive/my_training_logs/test.log', filemode='w')\n",
        "\n",
        "    # initialize model and model parameters\n",
        "    print(\"initialize model\")\n",
        "    unet = Unet(3).to(device)  # 3 RGB channels\n",
        "    optimizer = torch.optim.Adam(unet.parameters(), lr=0.0001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    dice_loss = MyLoss(dice_loss_mode=True, smooth=0.01)\n",
        "\n",
        "    for e in range(epoch):\n",
        "        for i in range(iteration):\n",
        "            # get train images and masks (we drop last few samples)\n",
        "            train_content, train_mask = load_data(train_img,\n",
        "                                                  start_idx=i * batch_size,\n",
        "                                                  shuffle=shuffle,\n",
        "                                                  batch_size=batch_size)\n",
        "\n",
        "            # rescaled content data and convert mask data into binary digit\n",
        "            train_content, train_mask = adjust_data(train_content, train_mask)\n",
        "\n",
        "            # create tensor matrix for model to train\n",
        "            # u cannot use torchvision.transforms.ToTensor() here because the function accept\n",
        "            # a three-dimensional input (CxHxW), but we have four dimensions (NxCxHxW)\n",
        "            train_content_tensor = torch.from_numpy(train_content).to(device)\n",
        "            train_mask_tensor = torch.from_numpy(train_mask).to(device)\n",
        "\n",
        "            # now our data is double(float64 in pytorch) while the weights in conv are float\n",
        "            # convert our data to float32\n",
        "            train_content_tensor = train_content_tensor.float()\n",
        "            train_mask_tensor = train_mask_tensor.float()\n",
        "\n",
        "            # train data\n",
        "            # set the model in the training mode\n",
        "            unet.train()\n",
        "            optimizer.zero_grad()  # clear grad, avoid accumulation\n",
        "            pred_mask_tensor = unet.forward(train_content_tensor)  # get model prediction\n",
        "            \n",
        "            # get prediction loss and accuracy\n",
        "            if use_cel:\n",
        "              loss = criterion(pred_mask_tensor, train_mask_tensor) + dice_loss(pred_mask_tensor, train_mask_tensor)\n",
        "            else:\n",
        "              loss = dice_loss(pred_mask_tensor, train_mask_tensor)\n",
        "            accuracy = dice_score(pred_mask_tensor, train_mask_tensor)\n",
        "\n",
        "            loss.backward()  # backpropagation\n",
        "            optimizer.step()  # update model weight\n",
        "            \n",
        "            # print training log\n",
        "            print('epoch-%s-iteration-%s: loss %s accuracy %s' % (e + 1, i + 1, loss.item(), accuracy.item()))  # print loss & accuracy\n",
        "            # calculate and print validation accuracy every other 10 iterations\n",
        "            if (i + 1) % interval == 0:\n",
        "                valid_dice_score, valid_iou_score = validation(unet, validation_img, device)\n",
        "                print('valid iou score: %s valid dice score: %s' % (valid_iou_score.item(), valid_dice_score.item()))\n",
        "                # save model if valid dice exceed 0.75\n",
        "                if valid_dice_score.item() > 0.85:\n",
        "                  torch.save({'model': unet.state_dict()}, 'unet_epoche%s_iter%s.pth' % (e + 1, i + 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOFRr9SFqqIr"
      },
      "source": [
        "Next we could train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9QUPx396ooz"
      },
      "outputs": [],
      "source": [
        "rewrite = False\n",
        "if rewrite:\n",
        "  path = \"/content/drive/MyDrive/kaggle_3m\"\n",
        "  # select all file paths into two dataframes\n",
        "  masks, contents = extract_paths(path)\n",
        "  # sort paths and combine dataframes\n",
        "  dir_df = sort_combine_paths(masks, contents)\n",
        "  # split training set, validation set and test set, not depend on patient id\n",
        "  train_dirs, test_dirs = train_test_split(dir_df, test_size=0.1)\n",
        "  test_dirs.to_csv(\"/content/drive/MyDrive/test.csv\")\n",
        "  train_dirs.to_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "  train_dirs, validation_dirs = train_test_split(train_dirs, test_size=0.2, random_state=40)\n",
        "else:\n",
        "  # read csv\n",
        "  train_dirs = pd.read_csv('/content/drive/MyDrive/My model 2/train.csv', index_col = 0)\n",
        "  train_dirs, validation_dirs = train_test_split(train_dirs, test_size=0.2, random_state=40)\n",
        "\n",
        "train(train_img=train_dirs, validation_img=validation_dirs, lrate=0.001, use_cel=True, epoch=10, batch_size=32, device_='cuda')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}